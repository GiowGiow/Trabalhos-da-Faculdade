{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando dataset: dados programas de Pós-graducação UFMG\n",
    "\n",
    "Este notebook tem como finalidade processar, unificar e transpor dados referentes aos programas de Pós-graduação da UFMG, tendo como fonte os dados abertos fornecidos pela plataforma Sucupira.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função: read_csv\n",
    "***Method***: Tem como objetivo ler um arquivo csv e transformá-lo em um dataFrame.<br><br>\n",
    "***Paramns***: Funcao recebe como parametro um caminho como o nome do arquivo(***path***), um separador de colunas (***separator***) e um encoding opcional (***encode_type***).<br><br>\n",
    "***Return***: Funcao tem como retorno um dataFrame.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataFrame(path, separator=';', encode_type='ISO-8859-1'):\n",
    "    alternate_sep = ','\n",
    "    try:\n",
    "        return pd.read_csv(path, engine='c', sep=separator, encoding=encode_type)\n",
    "    except Exception as ex:\n",
    "        # A partir de um ano ai eles resolveram: vamo mudar pra ,\n",
    "        #print(ex)\n",
    "        return pd.read_csv(path, engine='c', sep=alternate_sep, encoding=encode_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função: merge_data_frame\n",
    "***Method***: Tem como objetivo unir todos os arquivos CSV de uma determinada categória<br><br>\n",
    "***Paramns***: Funcao recebe como parametro: \n",
    "\n",
    "    * um caminho como o nome do arquivo(***path_type***),\n",
    "    * um separador de colunas (***slice_data***)\n",
    "    * um encoding opcional (***list_columns***).\n",
    "    * um encoding opcional (***list_new_columns***).\n",
    "    * um encoding opcional (***drop_dup***).\n",
    "\n",
    "***Return***: Funcao tem como retorno um dataFrame.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_frame(path_type, slice_data, list_columns, list_new_columns, drop_dup = False, drop_nan=False, encode_type=\"ISO-8859-1\"):\n",
    "\n",
    "    # default do drop dup e false para evitar que ele ignore o dataset das teses\n",
    "    \n",
    "    # Define directory \n",
    "    path_year_list = os.listdir(path_type)\n",
    "\n",
    "    # Empty data frame\n",
    "    df_merge = pd.DataFrame({})\n",
    "\n",
    "    # Procces list of file in currente year\n",
    "    for file in path_year_list:\n",
    "        df = None\n",
    "            \n",
    "        # Read a csv file\n",
    "        df = read_dataFrame(path_type + file, encode_type=encode_type)\n",
    "\n",
    "        # Query for UFMG\n",
    "        df = df.query(slice_data)\n",
    "\n",
    "        # Slice data frame\n",
    "        df = df[list_columns]\n",
    "        \n",
    "        df.columns = list_new_columns\n",
    "        \n",
    "        # Checa se ele vai dropar as linhas duplicadas\n",
    "        if drop_dup == True:\n",
    "            df = df.drop_duplicates()\n",
    "        \n",
    "        # Checa se ele vai remover linhas com entradas invalidas\n",
    "        if drop_nan == True:\n",
    "            df = df.dropna()\n",
    "        \n",
    "        # Concat data frame\n",
    "        df_merge = pd.concat([df_merge,df])\n",
    "            \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função: mapDataFrame\n",
    "***Method***: Tem como objetivo realizar um mapeamento no data frame<br><br>\n",
    "***Paramns***: Funcao recebe como parametro: \n",
    "\n",
    "    * um caminho como o nome do arquivo(***path_type***),\n",
    "    * um separador de colunas (***slice_data***)\n",
    "    * um encoding opcional (***list_columns***).\n",
    "    * um encoding opcional (***list_new_columns***).\n",
    "    * um encoding opcional (***drop_dup***).\n",
    "\n",
    "***Return***: Funcao tem como retorno um dataFrame.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapDataFrame(df, groupList, columnsName, listAgg=None, dropColList=None):\n",
    "    \n",
    "    # Dimensao do dataframe\n",
    "    n = df.shape[0]\n",
    "    mapValues = {}\n",
    "\n",
    "    for i in range(n):\n",
    "        # Define uma chave para mapeamento do dataframe\n",
    "        key = ''\n",
    "        for val in groupList:\n",
    "            try:\n",
    "                key = key +\"\"+str(int(df.iloc[i,val]))\n",
    "            except:\n",
    "                key = key +\"\"+str(df.iloc[i,val])\n",
    "        \n",
    "        # Checa se a chave ja existe\n",
    "        if key in mapValues:        \n",
    "            if listAgg is None:\n",
    "                # Adiciona no final da lista o atributo de contagem de ocorrencias\n",
    "                mapValues[key][-1] += 1\n",
    "            else:\n",
    "                # Define tamanho do slice\n",
    "                l = len(listAgg)*-1\n",
    "                \n",
    "                for j in range(len(listAgg)):\n",
    "                    # Indice da coluna a ser somando\n",
    "                    k = listAgg[j]\n",
    "\n",
    "                    # Valor na posicao desejada\n",
    "                    contVal = df.iloc[i, l]\n",
    "\n",
    "                    # Soma coluna desejada\n",
    "                    mapValues[key][l] =  mapValues[key][l] + contVal\n",
    "\n",
    "                    # Incrementa indice de slice\n",
    "                    l += 1\n",
    "        else:\n",
    "            # Recebe lista de valores para a linhda do dataFrame\n",
    "            listVal = list(df.iloc[i,:].values)\n",
    "            \n",
    "            # Adiciona key como valor\n",
    "            listVal.append(key)\n",
    "            \n",
    "            if listAgg is None:\n",
    "                # Adiciona no final da lista o atributo de contagem de ocorrencias\n",
    "                listVal.append(1)\n",
    "            else:\n",
    "                for j in range(len(listAgg)):\n",
    "                    # Indice da coluna a ser somando\n",
    "                    k = listAgg[j]\n",
    "                    listVal.append(df.iloc[i, k])\n",
    "            \n",
    "            mapValues.update({key: listVal})\n",
    "    \n",
    "    df = pd.DataFrame(data=mapValues).T\n",
    "\n",
    "    # Verifica se a opcao de remover colunas foi requisitada\n",
    "    if dropColList:\n",
    "        df = df.drop(df.columns[listAgg], axis = 1)\n",
    "        \n",
    "    df.columns = columnsName\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processando teses e dissetações dos programas de Pós-graduação\n",
    "***Fonte:*** https://dadosabertos.capes.gov.br/group/banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty data frame\n",
    "df_merge = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1987-2012  - Teses e Dissertacoes\n",
    "path_type = \"../capes/teses_dissertacoes_programa/1987-2012/\"\n",
    "slice_data = \"SiglaIes == 'UFMG'\"\n",
    "list_columns = ['Nivel', 'IdPrograma','NomePrograma', 'AnoBase']\n",
    "list_new_columns = ['Nivel', 'CodigoPrograma','NomePrograma', 'AnoBase']\n",
    "\n",
    "# Le as dataframes da pasta e da merge dataframes\n",
    "df = merge_data_frame(path_type, slice_data, list_columns, list_new_columns)\n",
    "\n",
    "# Remove Mestrados Profissionais e profissionalizantes\n",
    "df = df[df.Nivel != 'MESTRADO PROFISSIONAL']\n",
    "df = df[df.Nivel != 'Profissionalizante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lista de colunas para formar a chave de mapeamento\n",
    "listKey = [1,3]\n",
    "\n",
    "# Contando mestrado\n",
    "df_mestrado = mapDataFrame(df.query(\"Nivel == 'Mestrado'\"), listKey, columnsName=['Nivel', 'CodigoPrograma', 'NomePrograma', 'AnoBase','keyA',\"Dissertacao\"])\n",
    "\n",
    "# Contando mestrado\n",
    "df_doutorado = mapDataFrame(df.query(\"Nivel == 'Doutorado'\"), listKey, columnsName=['Nivel', 'CodigoPrograma', 'NomePrograma', 'AnoBase','keyA',\"Teses\"])\n",
    "\n",
    "# Realiza uniao dos dataFrames por atributo\n",
    "df_a = pd.merge(df_doutorado, df_mestrado, on=\"keyA\", how=\"outer\")\n",
    "\n",
    "# Junta os dataframes das teses\n",
    "df_merge = pd.concat([df_merge,df_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2013-2016 - Teses e Dissertacoes\n",
    "path_type = \"../capes/teses_dissertacoes_programa/2013-2016/\"\n",
    "slice_data = \"SG_ENTIDADE_ENSINO == 'UFMG'\"\n",
    "list_columns = ['NM_GRAU_ACADEMICO', 'CD_PROGRAMA', 'NM_PROGRAMA', 'AN_BASE']\n",
    "dict_agg = {'NomePrograma':['count']}\n",
    "list_new_columns = ['Nivel', 'CodigoPrograma','NomePrograma', 'AnoBase']\n",
    "\n",
    "# Le as dataframes da pasta e da merge dataframes\n",
    "df = merge_data_frame(path_type, slice_data, list_columns, list_new_columns)\n",
    "\n",
    "# Remove Mestrados Profissionais e profissionalizantes\n",
    "df = df[df.Nivel != 'MESTRADO PROFISSIONAL']\n",
    "df = df[df.Nivel != 'Profissionalizante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lista de colunas para formar a chave de mapeamento\n",
    "listKey = [1,3]\n",
    "\n",
    "# Contando mestrado\n",
    "df_mestrado = mapDataFrame(df.query(\"Nivel == 'MESTRADO'\"), listKey, columnsName=['Nivel', 'CodigoPrograma', 'NomePrograma', 'AnoBase','keyA',\"Dissertacao\"])\n",
    "\n",
    "# Contando mestrado\n",
    "df_doutorado = mapDataFrame(df.query(\"Nivel == 'DOUTORADO'\"), listKey, columnsName=['Nivel', 'CodigoPrograma', 'NomePrograma', 'AnoBase','keyA',\"Teses\"])\n",
    "\n",
    "# Realiza uniao dos dataFrames por atributo\n",
    "df_a = pd.merge(df_doutorado, df_mestrado, on=\"keyA\", how=\"outer\")\n",
    "\n",
    "# Junta os dataframes das teses\n",
    "df_merge = pd.concat([df_merge,df_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017-2018 - Teses e Dissertacoes\n",
    "path_type = \"../capes/teses_dissertacoes_programa/2017-2018/\"\n",
    "slice_data = \"SG_ENTIDADE_ENSINO == 'UFMG'\"\n",
    "list_columns = ['NM_GRAU_ACADEMICO', 'CD_PROGRAMA', 'NM_PROGRAMA', 'AN_BASE']\n",
    "dict_agg = {'NomePrograma':['count']}\n",
    "list_new_columns = ['Nivel', 'CodigoPrograma','NomePrograma', 'AnoBase']\n",
    "\n",
    "# Le os dataframes da pasta e da merge dataframes\n",
    "df = merge_data_frame(path_type, slice_data, list_columns, list_new_columns)\n",
    "\n",
    "# Remove Mestrados Profissionais e profissionalizantes\n",
    "df = df[df.Nivel != 'MESTRADO PROFISSIONAL']\n",
    "\n",
    "df = df[df.Nivel != 'Profissionalizante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lista de colunas para formar a chave de mapeamento\n",
    "listKey = [1,3]\n",
    "\n",
    "# Contando mestrado\n",
    "df_mestrado = mapDataFrame(df.query(\"Nivel == 'MESTRADO'\"), listKey, columnsName=['Nivel', 'CodigoPrograma', 'NomePrograma', 'AnoBase','keyA',\"Dissertacao\"])\n",
    "\n",
    "# Contando mestrado\n",
    "df_doutorado = mapDataFrame(df.query(\"Nivel == 'DOUTORADO'\"), listKey, columnsName=['Nivel', 'CodigoPrograma', 'NomePrograma', 'AnoBase','keyA',\"Teses\"])\n",
    "\n",
    "# Realiza uniao dos dataFrames por atributo\n",
    "df_a = pd.merge(df_doutorado, df_mestrado, on=\"keyA\", how=\"outer\")\n",
    "\n",
    "# Junta os dataframes das teses\n",
    "df_merge = pd.concat([df_merge,df_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta df para nosso dataset\n",
    "df_merge.to_excel('./datasets/teses_dissertacao-ufmg.xlsx')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processando produção dos programas de Pós-graduação\n",
    "***Fonte:*** https://dadosabertos.capes.gov.br/group/producao-intelectual-da-pos-graduacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty data_frame to merge data\n",
    "df_merge = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produtividade do programa - 2004 - 2012\n",
    "path_type = \"../capes/produtividade_programa/2004-2012/\"\n",
    "slice_data = \"SG_ENTIDADE_ENSINO == 'UFMG'\"\n",
    "list_columns = ['NM_PROGRAMA_IES', 'CD_PROGRAMA_IES','AN_BASE','NM_PRODUCAO','NM_TIPO_PRODUCAO']\n",
    "dict_agg = {'NomePrograma':['count']}\n",
    "list_new_columns = ['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao']\n",
    "\n",
    "# Combina os dataframes das pastas\n",
    "df = merge_data_frame(path_type, slice_data, list_columns, list_new_columns, drop_dup=False)\n",
    "\n",
    "# Removo duplicatas da coluna nome producao, ou seja, tiro nomes repetidos\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lista de colunas para formar a chave de mapeamento\n",
    "listKey = [1,2]\n",
    "\n",
    "# Contando producao Artistica\n",
    "df_artistica = mapDataFrame(df.query(\"TipoProducao == 'ARTÍSTICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma', 'AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesArtisticas\"])\n",
    "\n",
    "# Contando producao Bibliografica\n",
    "df_bibliografica = mapDataFrame(df.query(\"TipoProducao == 'BIBLIOGRÁFICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesBibliograficas\"])\n",
    "\n",
    "# Contando producao Tecnica\n",
    "df_tecnica = mapDataFrame(df.query(\"TipoProducao == 'TÉCNICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesTecnicas\"])\n",
    "\n",
    "# Realiza uniao dos dataFrames por atributo\n",
    "df_a = pd.merge(df_artistica, df_bibliografica, on=\"keyA\", how=\"outer\")\n",
    "df_a = pd.merge(df_a, df_tecnica, on=\"keyA\", how=\"outer\")\n",
    "\n",
    "# Junta os dataframes das teses\n",
    "df_merge = pd.concat([df_merge,df_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produtividade do programa - 2013 - 2016\n",
    "path_type = \"../capes/produtividade_programa/2013-2016/\"\n",
    "slice_data = \"SG_ENTIDADE_ENSINO == 'UFMG'\"\n",
    "list_columns = ['NM_PROGRAMA_IES', 'CD_PROGRAMA_IES','AN_BASE','NM_PRODUCAO','NM_TIPO_PRODUCAO']\n",
    "dict_agg = {'NomePrograma':['count']}\n",
    "list_new_columns = ['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao']\n",
    "\n",
    "# Combina os dataframes das pastas\n",
    "df = merge_data_frame(path_type, slice_data, list_columns, list_new_columns, drop_dup=False)\n",
    "\n",
    "# Removo duplicatas da coluna nome producao, ou seja, tiro nomes repetidos\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lista de colunas para formar a chave de mapeamento\n",
    "listKey = [1,2]\n",
    "\n",
    "# Contando producao Artistica\n",
    "df_artistica = mapDataFrame(df.query(\"TipoProducao == 'ARTÍSTICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma', 'AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesArtisticas\"])\n",
    "\n",
    "# Contando producao Bibliografica\n",
    "df_bibliografica = mapDataFrame(df.query(\"TipoProducao == 'BIBLIOGRÁFICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesBibliograficas\"])\n",
    "\n",
    "# Contando producao Tecnica\n",
    "df_tecnica = mapDataFrame(df.query(\"TipoProducao == 'TÉCNICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesTecnicas\"])\n",
    "\n",
    "# Realiza uniao dos dataFrames por atributo\n",
    "df_a = pd.merge(df_artistica, df_bibliografica, on=\"keyA\", how=\"outer\")\n",
    "df_a = pd.merge(df_a, df_tecnica, on=\"keyA\", how=\"outer\")\n",
    "\n",
    "# Junta os dataframes das teses\n",
    "df_merge = pd.concat([df_merge,df_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produtividade do programa - 2017 - 2020\n",
    "path_type = \"../capes/produtividade_programa/2017-2020/\"\n",
    "slice_data = \"SG_ENTIDADE_ENSINO == 'UFMG'\"\n",
    "list_columns = ['NM_PROGRAMA_IES', 'CD_PROGRAMA_IES','AN_BASE','NM_PRODUCAO','NM_TIPO_PRODUCAO']\n",
    "dict_agg = {'NomePrograma':['count']}\n",
    "list_new_columns = ['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao']\n",
    "\n",
    "# Combina os dataframes das pastas\n",
    "df = merge_data_frame(path_type, slice_data, list_columns, list_new_columns, drop_dup=False)\n",
    "\n",
    "# Removo duplicatas da coluna nome producao, ou seja, tiro nomes repetidos\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lista de colunas para formar a chave de mapeamento\n",
    "listKey = [1,2]\n",
    "\n",
    "# Contando producao Artistica\n",
    "df_artistica = mapDataFrame(df.query(\"TipoProducao == 'ARTÍSTICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma', 'AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesArtisticas\"])\n",
    "\n",
    "# Contando producao Bibliografica\n",
    "df_bibliografica = mapDataFrame(df.query(\"TipoProducao == 'BIBLIOGRÁFICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesBibliograficas\"])\n",
    "\n",
    "# Contando producao Tecnica\n",
    "df_tecnica = mapDataFrame(df.query(\"TipoProducao == 'TÉCNICA'\"), listKey, columnsName=['NomePrograma', 'CodigoPrograma','AnoBase', 'NomeProducao','TipoProducao','keyA',\"ProducoesTecnicas\"])\n",
    "\n",
    "# Realiza uniao dos dataFrames por atributo\n",
    "df_a = pd.merge(df_artistica, df_bibliografica, on=\"keyA\", how=\"outer\")\n",
    "df_a = pd.merge(df_a, df_tecnica, on=\"keyA\", how=\"outer\")\n",
    "\n",
    "# Junta os dataframes das teses\n",
    "df_merge = pd.concat([df_merge,df_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_excel('./datasets/produtividade_do_programa.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processando dado sobre bolsas \n",
    "***Fonte:*** https://geocapes.capes.gov.br/geocapes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty data_frame to merge data\n",
    "df_merge = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsas GeoCapes\n",
    "path_type = \"../capes/geocapes/\"\n",
    "slice_data = \"IES == 'UFMG'\"\n",
    "list_columns = ['Ano','Código Programa', 'Programa','DOUTORADO PLENO', 'MESTRADO']\n",
    "dict_agg = {'Programa':['count']}\n",
    "list_new_columns = ['AnoBase','CodigoPrograma','Programa','BolsasDoutorado', 'BolsasMestrado']\n",
    "\n",
    "# Combina os dataframes das pastas\n",
    "df = merge_data_frame(path_type, slice_data, list_columns, list_new_columns, drop_dup=True, drop_nan=True, encode_type=\"utf-8\")\n",
    "\n",
    "# Define lista de colunas para formar a chave de mapeamento\n",
    "listKey = [1,0]\n",
    "\n",
    "# Define lista de colunas a serem somadas\n",
    "listSum = [3,4]\n",
    "\n",
    "# Contando mestrado\n",
    "df_merge = mapDataFrame(df, listKey, columnsName=['AnoBase','CodigoPrograma','NomePrograma','keyA','BolsasDoutorado', 'BolsasMestrado'], listAgg=listSum, dropColList=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_excel('./datasets/bolsas_programas.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando datasets:\n",
    "#### Producao, Teses/Dissertações, Bolsas, Valor das Bolsas, Nota Capes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando resultado para teses\n",
    "df_producao = pd.read_excel('./datasets/produtividade_do_programa.xlsx')\n",
    "df_producao.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando resultado para teses\n",
    "df_teses = pd.read_excel('./datasets/teses_dissertacao-ufmg.xlsx')\n",
    "df_teses.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando resultado para teses\n",
    "df_bolsas = pd.read_excel('./datasets/bolsas_programas.xlsx')\n",
    "df_bolsas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "df_merge = pd.merge(df_producao, df_teses, on=\"keyA\", how=\"outer\")\n",
    "df_merge = pd.merge(df_merge, df_bolsas, on=\"keyA\", how=\"outer\")\n",
    "df_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valores = read_dataFrame('./datasets/valor_bolsas.csv',\";\")\n",
    "df_valores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multVal(df, df_valores):\n",
    "    \n",
    "    n = df_valores.shape[0]\n",
    "    bolsaAno= {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        ano = str(int(df_valores.loc[i,\"AnoBase\"]))\n",
    "        bolsaAno.update({ano: list(df_valores.iloc[i,1:])})\n",
    "    \n",
    "    n = df.shape[0]\n",
    "    \n",
    "    valDoutorado = []\n",
    "    valMestrado = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        ano = str(int(df.loc[i,\"AnoBase_y_x\"]))\n",
    "        mestrado = df.loc[i,\"BolsasMestrado\"]\n",
    "        doutorado = df.loc[i,\"BolsasDoutorado\"]\n",
    "        \n",
    "        if ano in bolsaAno:\n",
    "            anualMestrado = mestrado*bolsaAno[ano][1]*12\n",
    "            anualDoutorado = doutorado*bolsaAno[ano][0]*12\n",
    "            \n",
    "            valDoutorado.append(anualDoutorado)\n",
    "            valMestrado.append(anualMestrado)\n",
    "            \n",
    "        else:\n",
    "            valDoutorado.append(0)\n",
    "            valMestrado.append(0)\n",
    "    \n",
    "    df = df.assign(valor_anual_bolsa_doutorado = valDoutorado)\n",
    "    df = df.assign(valor_anual_bolsa_mestrado = valMestrado)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df_merge = df_merge.fillna(0)\n",
    "df_valores = multVal(df_merge, df_valores)\n",
    "df_valores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "df_merge = pd.merge(df_merge, df_valores, on=\"keyA\", how=\"outer\")\n",
    "df_merge.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo notas Capes para anos correspondentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Abrindando arquivo com notas capes\n",
    "df_nota = pd.read_excel('./datasets/notas_programas_capes.xlsx')\n",
    "\n",
    "# Ordena dataFrame    \n",
    "df_nota = df_nota.sort_values([\"keyA\",\"AnoBase\"])\n",
    "\n",
    "a = {}\n",
    "n = df_nota.shape[0]\n",
    "\n",
    "# Cria coluna com anos que não houve avaliacao qaudrienal\n",
    "for i in range(n):\n",
    "    codigoPrograma = df_nota.iloc[i,2]\n",
    "    ano = df_nota.iloc[i,0]\n",
    "    \n",
    "    if codigoPrograma in a:\n",
    "        a[codigoPrograma]\n",
    "        a[codigoPrograma].update({\"CodigoPrograma\" : codigoPrograma})\n",
    "        a[codigoPrograma].update({ano : list(df_nota.iloc[i,-2:])})\n",
    "    else:\n",
    "        a.update({codigoPrograma : {}})\n",
    "        a[codigoPrograma].update({\"CodigoPrograma\" : codigoPrograma})\n",
    "        a[codigoPrograma].update({ano : list(df_nota.iloc[i,-2:])})\n",
    "        \n",
    "        \n",
    "result = pd.DataFrame(data=a).T \n",
    "n, m = result.shape\n",
    "anos = result.columns\n",
    "\n",
    "# Transforma valores NaN in 0\n",
    "result = result.fillna(0)\n",
    "\n",
    "# Define nota para anos que não houve avaliacao quadrienal\n",
    "for i in range(n):\n",
    "    codigoPrograma = result.iloc[i,1]\n",
    "    for j in  range(m):\n",
    "        if result.iloc[i,j] == 0:\n",
    "            result.iloc[i,j] = result.iloc[i,j-1]\n",
    "\n",
    "b = {}\n",
    "for i in range(n):\n",
    "    codigoPrograma = result.iloc[i,0]\n",
    "\n",
    "    for j in  range(m):\n",
    "        ano = anos[j]\n",
    "        val = result.iloc[i,j]\n",
    "        \n",
    "        if val[0] == 0:\n",
    "            val = [0,0]\n",
    "        \n",
    "        if codigoPrograma in b:\n",
    "            rowList = [codigoPrograma,ano,val[0],val[1]]\n",
    "            b[codigoPrograma].append(rowList)\n",
    "        else:\n",
    "            b.update({codigoPrograma: list()})\n",
    "            rowList = [codigoPrograma, ano, val[0],val[1]]\n",
    "            b[codigoPrograma].append(rowList)\n",
    "\n",
    "c = []\n",
    "\n",
    "# Transforma dicionario em lista    \n",
    "for key in b.keys():\n",
    "    for i in range(1,len(b[key])):\n",
    "        c.append(b[key][i])\n",
    "\n",
    "df_notas = pd.DataFrame(c, columns =['CodigoPrograma','AnoBase', 'NotaCapesDoutorado','NotaCapesMestrado']) \n",
    "df_notas['keyA'] = df_notas['CodigoPrograma'] + df_notas['AnoBase'].astype(str)\n",
    "df_notas = df_notas.query(\"AnoBase !='2019'\")\n",
    "df_notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "df_merge = pd.merge(df_merge, df_notas, on=\"keyA\", how=\"outer\")\n",
    "df_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Função une colunas que tiveram clash nos full joins e coloca elas e retorna uma coluna.\n",
    "Recebe um data frame, as colunas para serem unidas e o tamanho do dataframe\n",
    "'''\n",
    "def recreate_column(df, list_of_cols, shape):\n",
    "    coluna = ['NaN']* shape\n",
    "    for index, row in df.iterrows():\n",
    "        for col in list_of_cols:\n",
    "            valor = str(row[col]).lower()\n",
    "            if valor == \"0\" or valor == \"nan\" or valor == \"0.0\":\n",
    "                continue\n",
    "            else:\n",
    "                #print(valor, type(valor))\n",
    "                coluna[index] = valor\n",
    "    return coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_prog = ['AnoBase', 'AnoBase_x_x', 'AnoBase_x_x_x', 'AnoBase_x_x_y', 'AnoBase_x_y', 'AnoBase_x_y_x', 'AnoBase_x_y_y', 'AnoBase_y_x', 'AnoBase_y_x_x', 'AnoBase_y_x_y', 'AnoBase_y_y', 'AnoBase_y_y_x', 'AnoBase_y_y_y']\n",
    "codigo_prog = ['CodigoPrograma', 'CodigoPrograma_x_x', 'CodigoPrograma_x_x_x', 'CodigoPrograma_x_x_y', 'CodigoPrograma_x_y', 'CodigoPrograma_x_y_x', 'CodigoPrograma_x_y_y', 'CodigoPrograma_y_x', 'CodigoPrograma_y_x_x', 'CodigoPrograma_y_x_y', 'CodigoPrograma_y_y', 'CodigoPrograma_y_y_x', 'CodigoPrograma_y_y_y']\n",
    "nome_prog = ['NomePrograma_x_x', 'NomePrograma_x_x_x', 'NomePrograma_x_x_y', 'NomePrograma_x_y', 'NomePrograma_x_y_x', 'NomePrograma_x_y_y', 'NomePrograma_y_x', 'NomePrograma_y_x_x', 'NomePrograma_y_x_y', 'NomePrograma_y_y', 'NomePrograma_y_y_x', 'NomePrograma_y_y_y']\n",
    "\n",
    "# Recria as colunas\n",
    "anos = recreate_column(df_merge, ano_prog, df_merge.shape[0])\n",
    "codigo = recreate_column(df_merge, codigo_prog, df_merge.shape[0])\n",
    "nome_prog = recreate_column(df_merge, nome_prog, df_merge.shape[0])\n",
    "\n",
    "# Reinsere as colunas\n",
    "df_merge['AnoBase'] = anos\n",
    "df_merge['CodigoPrograma'] = codigo\n",
    "df_merge['NomePrograma'] = nome_prog\n",
    "\n",
    "# Ordena as colunas\n",
    "df_merge = df_merge.sort_index(axis=1)\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas finais\n",
    "colsToKeep =[\n",
    " 'keyA',\n",
    " 'AnoBase',\n",
    " 'BolsasDoutorado_x',\n",
    " 'BolsasMestrado_x',\n",
    " 'CodigoPrograma',\n",
    " 'Dissertacao_x',\n",
    " 'NomePrograma',\n",
    " 'NotaCapesDoutorado',\n",
    " 'NotaCapesMestrado',\n",
    " 'ProducoesArtisticas_x',\n",
    " 'ProducoesBibliograficas_x',\n",
    " 'ProducoesTecnicas_x',\n",
    " 'Teses_x',\n",
    " 'valor_anual_bolsa_doutorado',\n",
    " 'valor_anual_bolsa_mestrado'\n",
    "]\n",
    "\n",
    "\n",
    "df_merge = df_merge.loc[:,colsToKeep]\n",
    "\n",
    "# Renomeio Colunas\n",
    "df_merge.columns = [\n",
    "    'Chave',\n",
    "    'AnoBase',\n",
    "    'BolsasDoutorado',\n",
    "    'BolsasMestrado',\n",
    "    'CodigoPrograma',\n",
    "    'Dissertacao',\n",
    "    'NomePrograma',\n",
    "    'NotaCapesDoutorado',\n",
    "    'NotaCapesMestrado',\n",
    "    'ProducoesArtisticas',\n",
    "    'ProducoesBibliograficas',\n",
    "    'ProducoesTecnicas',\n",
    "    'NumTeses',\n",
    "    'ValorAnualBolsaDoutorado',\n",
    "    'ValorAnualBolsaMestrado'\n",
    "]\n",
    "\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta dataset limpo\n",
    "df_merge.to_excel('./datasets/dados_posGraduacao_UFMG.xlsx')\n",
    "df_merge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
